{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pidipidi/cs577_RLI/blob/master/PDDL_Planner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classical Task Planner using PDDL\n",
        "\n",
        "This notebook covers the implementation of a classical symbolic task planner using PDDL (Planning Domain Definition Language) and its integration with [AI2-THOR simulation](https://ai2thor.allenai.org/).\n",
        "Within the AI2-THOR kitchen environment, we employ PDDL to formulate and solve two distinct task‐planning problems, executing the generated plans to achieve their respective goals.\n",
        "\n",
        "---\n",
        "\n",
        "## Objectives\n",
        "\n",
        "- Define task context files and initialize AI2-THOR scenes  \n",
        "- Author PDDL **domain** and **problem** files for each task  \n",
        "- Generate optimal plans with **Pyperplan** (A* + FF heuristic)  \n",
        "- Parse the planner output into executable action objects  \n",
        "- Execute and verify each plan inside AI2-THOR  \n",
        "- Record per-step logs and RGB frames, then compile them into an MP4 for visual inspection\n",
        "  \n",
        "\n",
        "---\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "- Environment Setup  \n",
        "- **Task 1: storeUtensils**  \n",
        "   1. Task Context & Environment Setup  \n",
        "   2. Define PDDL Domain & Problem  \n",
        "   3. Run Planner & Inspect Solution  \n",
        "   4. Execute in AI2-THOR  \n",
        "   5. Record Execution & Create Video  \n",
        "\n",
        "- **Task 2: serveCoffee**  \n",
        "   1. Task Context & Environment Setup  \n",
        "   2. Define PDDL Domain & Problem  \n",
        "   3. Run Planner & Inspect Solution  \n",
        "   4. Execute in AI2-THOR  \n",
        "   5. Record Execution & Create Video   \n",
        "\n",
        "---\n",
        "\n",
        "> **Note:** Run cells in order. Editable code cells allow you to tweak parameters or actions for hands-on experimentation.  \n"
      ],
      "metadata": {
        "id": "tdNfGIdB8WCC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🚨 Runtime Type Notice\n",
        "\n",
        "AI2-THOR requires a **CPU** runtime in Colab.  \n",
        "Please go to **Runtime → Change runtime type** and select **CPU** before running any cells."
      ],
      "metadata": {
        "id": "W-kKG2MJKcAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Environment Setup"
      ],
      "metadata": {
        "id": "FzN_8FDD1kNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This tutorial uses an AI2THOR environment. To create the environment, upload the AI2THOR.zip file from the designated repository to your local machine. Run the code block below to upload the necessary files to your Colab.\n",
        "\n",
        "*   AI2THOR.zip"
      ],
      "metadata": {
        "id": "gTfFlAOZQtf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "ltpNX11LQiqq",
        "outputId": "228b2e55-947f-4a13-ae4f-f445facdeff1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ac4abe08-862c-4b1e-9e6a-35a5d8ee5d5c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ac4abe08-862c-4b1e-9e6a-35a5d8ee5d5c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2535520808.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 2. Change working directory to /content\n",
        "%cd /content\n",
        "\n",
        "# 3. Unzip the project archive from Drive\n",
        "!unzip \"/content/AI2THOR_ws.zip\"\n",
        "%cd AI2THOR_ws\n",
        "\n",
        "# 4. Install required Python package\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "wCH8MYBvsJEq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "296d1626-28fd-4dfa-ef6b-becbffe79e98"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Archive:  /content/AI2THOR_ws.zip\n",
            "replace AI2THOR_ws/task_planning/environments/serveCoffee.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: /content/AI2THOR_ws\n",
            "Collecting ai2thor (from -r requirements.txt (line 1))\n",
            "  Downloading ai2thor-5.0.0-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (1.99.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (5.1.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.13.2)\n",
            "Collecting pyperplan (from -r requirements.txt (line 7))\n",
            "  Downloading pyperplan-2.1-py2.py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (2.37.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (11.3.0)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.6.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (from ai2thor->-r requirements.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ai2thor->-r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from ai2thor->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ai2thor->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.11/dist-packages (from ai2thor->-r requirements.txt (line 1)) (4.5.0)\n",
            "Collecting botocore (from ai2thor->-r requirements.txt (line 1))\n",
            "  Downloading botocore-1.40.10-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting aws-requests-auth (from ai2thor->-r requirements.txt (line 1))\n",
            "  Downloading aws_requests_auth-0.4.3-py2.py3-none-any.whl.metadata (567 bytes)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from ai2thor->-r requirements.txt (line 1)) (1.1.1)\n",
            "Collecting python-xlib (from ai2thor->-r requirements.txt (line 1))\n",
            "  Downloading python_xlib-0.33-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from ai2thor->-r requirements.txt (line 1)) (4.12.0.88)\n",
            "Requirement already satisfied: werkzeug>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from ai2thor->-r requirements.txt (line 1)) (3.1.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 2)) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 2)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 2)) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 2)) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 2)) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 2)) (4.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers->-r requirements.txt (line 5)) (4.55.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers->-r requirements.txt (line 5)) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers->-r requirements.txt (line 5)) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers->-r requirements.txt (line 5)) (1.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers->-r requirements.txt (line 5)) (0.34.4)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn->-r requirements.txt (line 6)) (2.2.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from pyperplan->-r requirements.txt (line 7)) (0.45.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers->-r requirements.txt (line 5)) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers->-r requirements.txt (line 5)) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers->-r requirements.txt (line 5)) (1.1.7)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 5)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 5)) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 5)) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 5)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 5)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers->-r requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers->-r requirements.txt (line 5)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers->-r requirements.txt (line 5)) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers->-r requirements.txt (line 5)) (0.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=0.15.0->ai2thor->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ai2thor->-r requirements.txt (line 1)) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->ai2thor->-r requirements.txt (line 1)) (2.5.0)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from botocore->ai2thor->-r requirements.txt (line 1))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask->ai2thor->-r requirements.txt (line 1)) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask->ai2thor->-r requirements.txt (line 1)) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask->ai2thor->-r requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: python-utils>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from progressbar2->ai2thor->-r requirements.txt (line 1)) (3.9.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers->-r requirements.txt (line 5)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers->-r requirements.txt (line 5)) (3.6.0)\n",
            "Downloading ai2thor-5.0.0-py2.py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m600.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyperplan-2.1-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.5/69.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aws_requests_auth-0.4.3-py2.py3-none-any.whl (6.8 kB)\n",
            "Downloading botocore-1.40.10-py3-none-any.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_xlib-0.33-py2.py3-none-any.whl (182 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.2/182.2 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-xlib, pyperplan, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, nvidia-cusparse-cu12, nvidia-cudnn-cu12, botocore, aws-requests-auth, nvidia-cusolver-cu12, ai2thor\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed ai2thor-5.0.0 aws-requests-auth-0.4.3 botocore-1.40.10 jmespath-1.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 pyperplan-2.1 python-xlib-0.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install or upgrade the AI2-THOR and Colab extension Python packages\n",
        "!pip install --upgrade ai2thor ai2thor-colab &> /dev/null\n",
        "import ai2thor\n",
        "import ai2thor_colab\n",
        "\n",
        "# Bring in the Controller class and visualization utilities\n",
        "from ai2thor.controller import Controller\n",
        "from ai2thor_colab import (\n",
        "    plot_frames,\n",
        "    show_objects_table,\n",
        "    side_by_side,\n",
        "    overlay,\n",
        "    show_video\n",
        ")\n",
        "\n",
        "# Start the X-server for rendering in Colab\n",
        "ai2thor_colab.start_xserver()\n",
        "\"AI2-THOR Version: \" + ai2thor.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "ilayQCRoEyt8",
        "outputId": "f6c8f647-deff-49c3-edaf-e4e5aaa18808"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <progress value='100' max=\"100\", style='width: 100%'>\n",
              "                100\n",
              "            </progress>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AI2-THOR Version: 5.0.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Controller Instance\n",
        "controller = Controller()\n",
        "%cd task_planning/"
      ],
      "metadata": {
        "id": "4qvPmaLGJs2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: storeUtensils\n",
        "\n",
        "In this task, the agent must pick up a spoon and a fork placed on the countertop and store them in the drawer.\n",
        "\n",
        "The PDDL planner will generate a sequence of actions that are then executed and visualized within the AI2-THOR kitchen environment.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NO6I2tJxa6Mf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Task Context & Environment Setup\n",
        "\n"
      ],
      "metadata": {
        "id": "6S18h4Jk5WuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the task context for Task 1: storeUtensils\n",
        "task_context = {\n",
        "  \"task_idx\": 1,\n",
        "  \"task\": \"storeUtensils\",\n",
        "  \"scene\": \"FloorPlan2\",\n",
        "  \"robot_init_state\": {\n",
        "    \"position\": {\n",
        "      \"x\": 1.0,\n",
        "      \"y\": 0.9,\n",
        "      \"z\": -0.75\n",
        "    },\n",
        "    \"rotation\": {\n",
        "      \"x\": 0,\n",
        "      \"y\": 180.0,\n",
        "      \"z\": 0\n",
        "    },\n",
        "    \"horizon\": 50.0\n",
        "  },\n",
        "  \"objects_init_state\": [\n",
        "    {\n",
        "      \"objectType\": \"Fork\",\n",
        "      \"objectName\": \"Fork_40ceb846\",\n",
        "      \"position\": {\n",
        "        \"x\": 1.0,\n",
        "        \"y\": 0.93,\n",
        "        \"z\": -1.41\n",
        "      },\n",
        "      \"rotation\": {\n",
        "        \"x\": 0.0,\n",
        "        \"y\": -0.0,\n",
        "        \"z\": 0.0\n",
        "      },\n",
        "      \"property\": {}\n",
        "    },\n",
        "    {\n",
        "      \"objectType\": \"Spoon\",\n",
        "      \"objectName\": \"Spoon_ab4315e1\",\n",
        "      \"position\": {\n",
        "        \"x\": 0.89,\n",
        "        \"y\": 0.93,\n",
        "        \"z\": -1.41\n",
        "      },\n",
        "      \"rotation\": {\n",
        "        \"x\": 0.0,\n",
        "        \"y\": -0.0,\n",
        "        \"z\": 0.0\n",
        "      },\n",
        "      \"property\": {}\n",
        "    }\n",
        "  ]\n",
        "}\n"
      ],
      "metadata": {
        "id": "JeS6BT5da-9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the AI2-THOR controller to load the specified scene\n",
        "# and configure rendering parameters\n",
        "controller.reset(\n",
        "    scene = task_context[\"scene\"],\n",
        "    visibilityDistance=1.5,\n",
        "    gridSize=0.05,\n",
        "    fieldOfView=90,\n",
        "    width=500,\n",
        "    height=500,\n",
        "    renderDepthImage=False,\n",
        "    renderNormalsImage=False,\n",
        "    renderInstanceSegmentation=False,\n",
        "    renderSemanticSegmentation=False\n",
        ")\n",
        "\n",
        "# Prepare and send object poses to the controller\n",
        "object_poses = []\n",
        "for object_init_state in task_context[\"objects_init_state\"]:\n",
        "    object_poses.append(\n",
        "        {\n",
        "            \"objectName\": object_init_state[\"objectName\"],\n",
        "            \"position\": object_init_state[\"position\"],\n",
        "            \"rotation\": object_init_state[\"rotation\"],\n",
        "        }\n",
        "    )\n",
        "controller.step(action=\"SetObjectPoses\", objectPoses=object_poses)\n",
        "controller.step(action=\"Done\")\n",
        "\n",
        "# Teleport the agent to its initial position and orientation\n",
        "controller.step(\n",
        "    action=\"Teleport\",\n",
        "    position=task_context['robot_init_state']['position'],\n",
        "    rotation=task_context['robot_init_state']['rotation'],\n",
        "    horizon=task_context['robot_init_state']['horizon'],\n",
        "    standing=True,\n",
        ")\n",
        "\n",
        "# Render and display the current camera view\n",
        "plot_frames(controller.last_event)"
      ],
      "metadata": {
        "id": "6imSpAofbPZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Define PDDL Domain & Problem\n"
      ],
      "metadata": {
        "id": "m-Ij-Ux-blFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct the PDDL Domain\n",
        "\n",
        "Create a **single domain file** (`storeUtensils_domain.pddl`) that contains two sections—**Predicates** and **Action Schemas**—as described below.\n",
        "\n",
        "---\n",
        "\n",
        "### Predicates  \n",
        "List every **predicate**—that is, each unary or binary relationship/attribute—that can appear in the initial state, goal conditions, or within an action’s preconditions and effects.\n",
        "\n",
        "---\n",
        "\n",
        "### Action Schemas  \n",
        "Only **five** action names are permitted:\n",
        "\n",
        "1. `open`  \n",
        "2. `close`  \n",
        "3. `pick-up`  \n",
        "4. `place-on`  \n",
        "5. `place-in`  \n",
        "\n",
        "Every action must follow this exact template:\n",
        "\n",
        "```\n",
        "<action_name>           : Name of the action to define (e.g., ‘open’)\n",
        "<parameters>            : ?variable\n",
        "<conjunction-of-predicates> : All predicates that must hold before the action\n",
        "<add-and-delete-list>       : Predicates to add (+) or remove (–) after execution\n",
        "\n",
        "(:action <action_name>\n",
        "  :parameters (<parameters>)\n",
        "  :precondition (and\n",
        "    <conjunction-of-predicates>\n",
        "  )\n",
        "  :effect (and\n",
        "    <add-and-delete-list>\n",
        "  )\n",
        ")\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "lwFe5jq8Bnb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the PDDL domain\n",
        "store_utensils_domain = \"\"\"; store-utensils_domain.pddl\n",
        "\n",
        "(define (domain store-utensils)\n",
        "  (:requirements :strips)\n",
        "\n",
        "  (:predicates\n",
        "    (at      ?o ?l)\n",
        "    (in      ?o ?c)\n",
        "    (holding ?o)\n",
        "    (arm-empty)\n",
        "    (open    ?c)\n",
        "    (closed  ?c)\n",
        "  )\n",
        "\n",
        "  (:action open\n",
        "    :parameters (?c)\n",
        "    :precondition (closed ?c)\n",
        "    :effect (and\n",
        "      (open   ?c)\n",
        "      (not (closed ?c))\n",
        "    )\n",
        "  )\n",
        "\n",
        "  (:action close\n",
        "    :parameters (?c)\n",
        "    :precondition (open ?c)\n",
        "    :effect (and\n",
        "      (closed ?c)\n",
        "      (not (open ?c))\n",
        "    )\n",
        "  )\n",
        "\n",
        "  (:action pick-up\n",
        "    :parameters (?o ?l)\n",
        "    :precondition (and\n",
        "      (at        ?o ?l)\n",
        "      (arm-empty)\n",
        "    )\n",
        "    :effect (and\n",
        "      (holding   ?o)\n",
        "      (not (at   ?o ?l))\n",
        "      (not (arm-empty))\n",
        "    )\n",
        "  )\n",
        "\n",
        "  (:action place-on\n",
        "    :parameters (?o ?l)\n",
        "    :precondition (holding ?o)\n",
        "    :effect (and\n",
        "      (at        ?o ?l)\n",
        "      (arm-empty)\n",
        "      (not (holding ?o))\n",
        "    )\n",
        "  )\n",
        "\n",
        "  (:action place-in\n",
        "    :parameters (?o ?c)\n",
        "    :precondition (and\n",
        "      (holding ?o)\n",
        "      (open    ?c)\n",
        "    )\n",
        "    :effect (and\n",
        "      (in      ?o ?c)\n",
        "      (arm-empty)\n",
        "      (not (holding ?o))\n",
        "    )\n",
        "  )\n",
        ")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "8mMqZ58abpvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Save the PDDL domain into a file\n",
        "with open(\"./pddl_files/storeUtensils_domain.pddl\", \"w\") as f:\n",
        "    f.write(store_utensils_domain)\n",
        "\n",
        "print(\"✅ storeUtensils_domain.pddl saved successfully!\")"
      ],
      "metadata": {
        "id": "Ml3tf-EycvAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct the PDDL Problem\n",
        "\n",
        "Create a **single problem file** (`storeUtensils_problem.pddl`) that references the domain you just wrote and contains three key sections—**Objects**, **Initial State**, and **Goal Conditions**—as described below.\n",
        "\n",
        "---\n",
        "\n",
        "### Objects (`:objects`)\n",
        "Declare every object (constant symbol) that participates in this specific planning instance.\n",
        "> 📌 Note: Use exactly the following names (no variations or additional objects):\n",
        ">\n",
        "> `spoon` `fork` `drawer` `countertop`\n",
        "---\n",
        "\n",
        "### Initial State (`:init`)  \n",
        "List all predicates that are **true** at the start of the episode.  \n",
        "> 📌 Note:\n",
        "> Even though the robotic arm is not visually rendered in the AI2-THOR scene, the planner should assume the agent starts in the arm-empty state.\n",
        "\n",
        "---\n",
        "\n",
        "### Goal Conditions (`:goal`)  \n",
        "Specify the conditions that must hold when planning finishes.  \n",
        "Wrap multiple predicates inside an `(and …)` expression.\n"
      ],
      "metadata": {
        "id": "fjh68RYMCI5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the PDDL problem\n",
        "store_utensils_problem = \"\"\"; store-utensils_problem.pddl\n",
        "\n",
        "(define (problem store-utensils-drawer)\n",
        "  (:domain store-utensils)\n",
        "\n",
        "  (:objects\n",
        "    spoon fork table drawer\n",
        "  )\n",
        "\n",
        "  (:init\n",
        "    (at        spoon table)\n",
        "    (at        fork  table)\n",
        "    (arm-empty)\n",
        "    (closed    drawer)\n",
        "  )\n",
        "\n",
        "  (:goal\n",
        "    (and\n",
        "      (in spoon drawer)\n",
        "      (in fork  drawer)\n",
        "    )\n",
        "  )\n",
        ")\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "Z9BDXMgJb-Tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Save the PDDL problem into a file\n",
        "with open(\"./pddl_files/storeUtensils_problem.pddl\", \"w\") as f:\n",
        "    f.write(store_utensils_problem)\n",
        "\n",
        "print(\"✅ storeUtensils_problem.pddl saved successfully!\")"
      ],
      "metadata": {
        "id": "2ykQCQR4dOBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Run Planner & Inspect Solution\n",
        "\n",
        "We use **Pyperplan**, an open-source Python planner, to derive a plan from the PDDL files. It searches the state space with heuristic A* and saves the resulting action sequence to a .soln file for inspection and later execution.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HT5pqdxlcPDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a plan and save it to a .soln file\n",
        "!pyperplan -l warning -s astar -H hff \\\n",
        "  ./pddl_files/storeUtensils_domain.pddl \\\n",
        "  ./pddl_files/storeUtensils_problem.pddl \\\n",
        "  > ./pddl_files/storeUtensils_problem.pddl.soln\n",
        "\n",
        "# Print the plan so you can verify the exact action sequence\n",
        "!cat ./pddl_files/storeUtensils_problem.pddl.soln"
      ],
      "metadata": {
        "id": "OChN8DbXcNJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Execute in AI2-THOR"
      ],
      "metadata": {
        "id": "V3310JphZYqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from ai2thor.controller import Controller\n",
        "from ai2thor.platform import Linux64, CloudRendering\n",
        "from actions import get_action_classes\n",
        "from plan_success_checker import check_task_success\n",
        "\n",
        "\n",
        "class Thor:\n",
        "    \"\"\"Thin wrapper around AI2-THOR’s Controller that:\n",
        "       • sets up the scene from a task-context dictionary\n",
        "       • executes high-level action classes (open, close, pick-up, …)\n",
        "       • logs events / RGB frames for later analysis or video creation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, task_context: dict, scenario_idx: int, records_dir: str):\n",
        "        \"\"\"Create a Thor helper and immediately initialize the simulator.\"\"\"\n",
        "        self.controller = None\n",
        "        self.counter = 0\n",
        "        self.task_context = task_context\n",
        "        self.records_dir = records_dir\n",
        "        self.log_archive = {}\n",
        "\n",
        "        # Available high-level actions (parsed from natural language commands).\n",
        "        self.action_space = get_action_classes()\n",
        "        self.init_env()\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # Environment setup\n",
        "    # ----------------------------------------------------------------------\n",
        "    def init_env(self):\n",
        "        \"\"\"Reset the AI2-THOR scene, place objects, and teleport the agent.\"\"\"\n",
        "        self.controller = Controller()\n",
        "        # Scene-level parameters (FOV, resolution, etc.)\n",
        "        self.controller.reset(\n",
        "            scene=self.task_context[\"scene\"],\n",
        "            visibilityDistance=1.5,\n",
        "            gridSize=0.05,\n",
        "            fieldOfView=90,\n",
        "            width=500,\n",
        "            height=500,\n",
        "            renderDepthImage=False,\n",
        "            renderNormalsImage=False,\n",
        "            renderInstanceSegmentation=False,\n",
        "            renderSemanticSegmentation=False,\n",
        "        )\n",
        "\n",
        "        # Place all task-specific objects at their initial poses\n",
        "        object_poses = [\n",
        "            {\n",
        "                \"objectName\": obj[\"objectName\"],\n",
        "                \"position\": obj[\"position\"],\n",
        "                \"rotation\": obj[\"rotation\"],\n",
        "            }\n",
        "            for obj in self.task_context[\"objects_init_state\"]\n",
        "        ]\n",
        "        self.controller.step(action=\"SetObjectPoses\", objectPoses=object_poses)\n",
        "        self.controller.step(action=\"Done\")\n",
        "\n",
        "        # Teleport the agent to its start pose (position, rotation, horizon)\n",
        "        self.controller.step(\n",
        "            action=\"Teleport\",\n",
        "            position=self.task_context[\"robot_init_state\"][\"position\"],\n",
        "            rotation=self.task_context[\"robot_init_state\"][\"rotation\"],\n",
        "            horizon=self.task_context[\"robot_init_state\"][\"horizon\"],\n",
        "            standing=True,\n",
        "        )\n",
        "        self.controller.step(action=\"Done\")\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # Convenience properties\n",
        "    # ----------------------------------------------------------------------\n",
        "    @property\n",
        "    def is_hand_empty(self) -> bool:\n",
        "        \"\"\"True if the agent is not holding any object.\"\"\"\n",
        "        return self.agent_state[\"isHolding\"] is None\n",
        "\n",
        "    @property\n",
        "    def agent_state(self) -> dict:\n",
        "        \"\"\"Return the current agent metadata with an extra 'isHolding' field.\"\"\"\n",
        "        event = self.controller.last_event\n",
        "        agent = event.metadata[\"agent\"]\n",
        "        agent[\"isHolding\"] = None\n",
        "        # Determine which object (if any) is currently picked up\n",
        "        for obj in self.objects_state:\n",
        "            if obj.get(\"pickupable\") and obj.get(\"isPickedUp\"):\n",
        "                agent[\"isHolding\"] = obj\n",
        "                break\n",
        "        return agent\n",
        "\n",
        "    @property\n",
        "    def objects_state(self) -> list:\n",
        "        \"\"\"Return metadata for all objects visible in the current frame.\"\"\"\n",
        "        return self.controller.last_event.metadata[\"objects\"]\n",
        "\n",
        "    @property\n",
        "    def rgb_frame(self) -> np.ndarray:\n",
        "        \"\"\"Return the current RGB image rendered by AI2-THOR.\"\"\"\n",
        "        return self.controller.last_event.frame\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # Object-lookup helpers\n",
        "    # ----------------------------------------------------------------------\n",
        "    def get_objectsByType(self, objectType: str) -> list:\n",
        "        \"\"\"Return all objects of a given AI2-THOR objectType.\"\"\"\n",
        "        return [o for o in self.objects_state if o[\"objectType\"].lower() == objectType.lower()]\n",
        "\n",
        "    def get_objectById(self, objectId: str):\n",
        "        \"\"\"Return a single object by its unique objectId (or None).\"\"\"\n",
        "        return next((o for o in self.objects_state if o[\"objectId\"] == objectId), None)\n",
        "\n",
        "    def get_objectByName(self, objectName: str):\n",
        "        \"\"\"Return a single object by its human-readable name (or None).\"\"\"\n",
        "        return next((o for o in self.objects_state if o[\"name\"] == objectName), None)\n",
        "\n",
        "    def get_closestObject(self, objects: list):\n",
        "        \"\"\"Given a list of objects, return the one closest to the agent.\"\"\"\n",
        "        agent_pos = self.agent_state[\"position\"]\n",
        "\n",
        "        def euclidean(p):\n",
        "            return ((p[\"x\"] - agent_pos[\"x\"]) ** 2 + (p[\"y\"] - agent_pos[\"y\"]) ** 2 + (p[\"z\"] - agent_pos[\"z\"]) ** 2) ** 0.5\n",
        "\n",
        "        return min(objects, key=lambda o: euclidean(o[\"position\"])) if objects else None\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # Logging utilities\n",
        "    # ----------------------------------------------------------------------\n",
        "    def log(self, success: bool, message: str):\n",
        "        \"\"\"Print and archive a log message for the current frame counter.\"\"\"\n",
        "        if not message:\n",
        "            return\n",
        "        tag = \"[INFO]\" if success else \"[ERROR]\"\n",
        "        msg = f\"Frame {self.counter:03d} | {tag} {message}\"\n",
        "        print(msg)\n",
        "        self.log_archive[self.counter] = msg\n",
        "\n",
        "    def save_data(self, log_flag: bool = True):\n",
        "        \"\"\"Save the current event + RGB frame and advance the frame counter.\"\"\"\n",
        "        if log_flag:\n",
        "            os.makedirs(f\"{self.records_dir}/events\", exist_ok=True)\n",
        "            with open(f\"{self.records_dir}/events/step_{self.counter}.pickle\", \"wb\") as f:\n",
        "                pickle.dump(self.controller.last_event, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "        os.makedirs(f\"{self.records_dir}/ego_img\", exist_ok=True)\n",
        "        plt.imsave(\n",
        "            f\"{self.records_dir}/ego_img/step_{self.counter}.png\",\n",
        "            np.asarray(self.rgb_frame, order=\"C\"),\n",
        "        )\n",
        "        self.counter += 1\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # Plan-parsing helpers\n",
        "    # ----------------------------------------------------------------------\n",
        "    def parse_word(self, line: str) -> str | None:\n",
        "        \"\"\"Convert a single PDDL action line into a natural-language command.\"\"\"\n",
        "        parts = line.strip(\"()\\n\").split()\n",
        "        mapping = {\n",
        "            \"pick-up\": lambda p: f\"pick up {p[1]}\",\n",
        "            \"place-in\": lambda p: f\"place {p[1]} in {p[2]}\",\n",
        "            \"place-on\": lambda p: f\"place {p[1]} on {p[2]}\",\n",
        "            \"open\": lambda p: f\"open {p[1]}\",\n",
        "            \"close\": lambda p: f\"close {p[1]}\",\n",
        "            \"turn-on\": lambda p: f\"turn on {p[1]}\",\n",
        "            \"turn-off\": lambda p: f\"turn off {p[1]}\",\n",
        "        }\n",
        "        return mapping.get(parts[0], lambda p: None)(parts)\n",
        "\n",
        "    def load_plan_from_soln(self, soln_path: str) -> list[str]:\n",
        "        \"\"\"Read a .soln file and return a list of natural-language commands.\"\"\"\n",
        "        commands = []\n",
        "        with open(soln_path) as f:\n",
        "            for line in f:\n",
        "                cmd = self.parse_word(line)\n",
        "                if cmd:\n",
        "                    commands.append(cmd)\n",
        "        return commands\n"
      ],
      "metadata": {
        "id": "63NGqoiTGNhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------------------\n",
        "# Main execution script\n",
        "# ---------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Initialize the AI2-THOR environment wrapper\n",
        "    thor = Thor(task_context, scenario_idx=-1, records_dir=\"test/storeUtensils/\")\n",
        "    time.sleep(1)  # brief pause to ensure the simulator is ready\n",
        "\n",
        "    # Read the planner output (.soln) and convert each line to a NL command\n",
        "    soln_path = \"pddl_files/storeUtensils_problem.pddl.soln\"\n",
        "    commands = thor.load_plan_from_soln(soln_path)\n",
        "\n",
        "    # Parse natural-language commands into concrete action objects\n",
        "    actions = []\n",
        "    for cmd in commands:\n",
        "        for action_cls in thor.action_space:\n",
        "            args = action_cls.parse(cmd)\n",
        "            if args is not None:\n",
        "                actions.append(action_cls(thor, args))\n",
        "                break\n",
        "\n",
        "    # Execute each action sequentially in the simulator\n",
        "    for idx, action in enumerate(actions, start=1):\n",
        "        print(f\"{idx}. Executing: {action}\")\n",
        "        action.execute()\n",
        "        thor.log(success=True, message=f\"after {action}\")"
      ],
      "metadata": {
        "id": "h7S2qHv2ceD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio, glob, os, numpy as np, PIL\n",
        "\n",
        "# Convert saved PNG frames into an MP4 video\n",
        "def make_video_from_frames(records_dir, output_fname=\"plan_execution.mp4\", fps=4):\n",
        "    img_dir = os.path.join(records_dir, \"ego_img\")\n",
        "    pngs = sorted(glob.glob(f\"{img_dir}/step_*.png\"),\n",
        "                  key=lambda p: int(os.path.splitext(os.path.basename(p))[0].split(\"_\")[-1]))\n",
        "    if not pngs:\n",
        "        print(\"No frames to make video.\")\n",
        "        return\n",
        "    out_path = os.path.join(records_dir, output_fname)\n",
        "    with imageio.get_writer(out_path, fps=fps) as writer:\n",
        "        for p in pngs:\n",
        "            img = PIL.Image.open(p).convert(\"RGB\")\n",
        "            writer.append_data(np.array(img))\n",
        "    print(f\"Saved video: {out_path}\")\n",
        "\n",
        "# Build the video\n",
        "if __name__ == \"__main__\":\n",
        "    make_video_from_frames(\n",
        "            records_dir=thor.records_dir,\n",
        "            output_fname=\"storeUtensils.mp4\",\n",
        "            fps=4\n",
        "        )"
      ],
      "metadata": {
        "id": "MiI7h5AOdQiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Play the execution video for the storeUtensils plan\n",
        "from IPython.display import Video\n",
        "Video(\"test/storeUtensils/storeUtensils.mp4\", embed=True, width=400)"
      ],
      "metadata": {
        "id": "nw_Yj48YdScE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2: serveCoffee\n",
        "\n",
        "In this task, the agent must take an empty mug from the countertop, fill it with coffee using the coffee machine, and then place the filled mug inside the refrigerator.\n",
        "\n",
        "The PDDL planner will generate a sequence of actions that are then executed and visualized within the AI2-THOR kitchen environment."
      ],
      "metadata": {
        "id": "vCqgD-2URpOH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Task Context & Environment Setup"
      ],
      "metadata": {
        "id": "vhoYjEbnMk5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the task context for Task 2: serveCoffee\n",
        "task_context = {\n",
        "  \"task_idx\": 2,\n",
        "  \"task\": \"serveCoffee\",\n",
        "  \"scene\": \"FloorPlan22\",\n",
        "  \"robot_init_state\": {\n",
        "    \"position\": {\n",
        "      \"x\": -2.0,\n",
        "      \"y\": 0.9,\n",
        "      \"z\": 0.4\n",
        "    },\n",
        "    \"rotation\": {\n",
        "      \"x\": 0,\n",
        "      \"y\": 270.0,\n",
        "      \"z\": 0\n",
        "    },\n",
        "    \"horizon\": 40.0\n",
        "  },\n",
        "  \"objects_init_state\": [\n",
        "    {\n",
        "      \"objectType\": \"CoffeeMachine\",\n",
        "      \"objectName\": \"CoffeeMachine_7eed2c49\",\n",
        "      \"position\": {\n",
        "        \"x\": -2.8,\n",
        "        \"y\": 0.9,\n",
        "        \"z\": 0.1\n",
        "      },\n",
        "      \"rotation\": {\n",
        "        \"x\": -0.0,\n",
        "        \"y\": 90.0,\n",
        "        \"z\": 0.0\n",
        "      },\n",
        "      \"property\": {}\n",
        "    },\n",
        "    {\n",
        "      \"objectType\": \"Mug\",\n",
        "      \"objectName\": \"Mug_7f8551ca\",\n",
        "      \"position\": {\n",
        "        \"x\": -2.4,\n",
        "        \"y\": 0.9,\n",
        "        \"z\": 0.24\n",
        "      },\n",
        "      \"rotation\": {\n",
        "        \"x\": 0.0,\n",
        "        \"y\": 0.0,\n",
        "        \"z\": 0.0\n",
        "      },\n",
        "      \"property\": {}\n",
        "    }\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "rJe8zRtPw9rC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the AI2-THOR controller to load the specified scene\n",
        "# and configure rendering parameters\n",
        "controller.reset(\n",
        "    scene = task_context[\"scene\"],\n",
        "    visibilityDistance=1.5,\n",
        "    gridSize=0.05,\n",
        "    fieldOfView=90,\n",
        "    width=500,\n",
        "    height=500,\n",
        "    renderDepthImage=False,\n",
        "    renderNormalsImage=False,\n",
        "    renderInstanceSegmentation=False,\n",
        "    renderSemanticSegmentation=False\n",
        ")\n",
        "\n",
        "# Prepare and send object poses to the controller\n",
        "object_poses = []\n",
        "for object_init_state in task_context[\"objects_init_state\"]:\n",
        "    object_poses.append(\n",
        "        {\n",
        "            \"objectName\": object_init_state[\"objectName\"],\n",
        "            \"position\": object_init_state[\"position\"],\n",
        "            \"rotation\": object_init_state[\"rotation\"],\n",
        "        }\n",
        "    )\n",
        "controller.step(action=\"SetObjectPoses\", objectPoses=object_poses)\n",
        "controller.step(action=\"Done\")\n",
        "\n",
        "# Teleport the agent to its initial position and orientation\n",
        "controller.step(\n",
        "    action=\"Teleport\",\n",
        "    position=task_context['robot_init_state']['position'],\n",
        "    rotation=task_context['robot_init_state']['rotation'],\n",
        "    horizon=task_context['robot_init_state']['horizon'],\n",
        "    standing=True,\n",
        ")\n",
        "\n",
        "# Render and display the current camera view\n",
        "plot_frames(controller.last_event)"
      ],
      "metadata": {
        "id": "7WFnkYAtwYHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Define PDDL Domain & Problem\n",
        "\n",
        "### Construct the PDDL Domain\n",
        "\n",
        "Create a **single domain file** (`serveCoffee_domain.pddl`) that contains two sections—**Predicates** and **Action Schemas**—as described below.\n",
        "\n",
        "---\n",
        "\n",
        "### Predicates  \n",
        "List every **predicate**—that is, each unary or binary relationship/attribute—that can appear in the initial state, goal conditions, or within an action’s preconditions and effects.\n",
        "\n",
        "---\n",
        "\n",
        "### Action Schemas  \n",
        "Only **five** action names are permitted:\n",
        "\n",
        "1. `open`  \n",
        "2. `close`  \n",
        "3. `pick-up`  \n",
        "4. `place-on`  \n",
        "5. `place-in`\n",
        "6. `turn-on`\n",
        "> 📌 Note:  \n",
        "> The `turn-on` action must take **two parameters**:\n",
        "> - `?d` device to activate (e.g., `coffeemachine`)  \n",
        "> - `?o` object that will be filled (e.g., `mug`)\n",
        "7. `turn-off`"
      ],
      "metadata": {
        "id": "Q4Bg4jszUmGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the PDDL domain\n",
        "serve_coffee_domain = \"\"\"; serve-coffee_domain.pddl\n",
        "\n",
        "(define (domain serve-coffee)\n",
        "  (:requirements :strips)\n",
        "\n",
        "  (:predicates\n",
        "    (at        ?o ?l)      ; object ?o is at location or device ?l\n",
        "    (holding   ?o)         ; robot is holding object ?o\n",
        "    (arm-empty)            ; robot arm is empty\n",
        "    (off       ?d)         ; device ?d is off\n",
        "    (on        ?d)         ; device ?d is on\n",
        "    (filled    ?o)         ; object ?o is filled with coffee\n",
        "    (open      ?c)         ; container ?c is open\n",
        "    (closed    ?c)         ; container ?c is closed\n",
        "    (surface   ?l)         ; place-on target\n",
        "    (container ?c)         ; place-in target\n",
        "  )\n",
        "\n",
        "  (:action pick-up\n",
        "    :parameters (?o ?l)\n",
        "    :precondition (and (at ?o ?l) (arm-empty))\n",
        "    :effect (and (holding ?o) (not (at ?o ?l)) (not (arm-empty)))\n",
        "  )\n",
        "\n",
        "  (:action place-on\n",
        "    :parameters (?o ?l)\n",
        "    :precondition (and (holding ?o) (surface ?l))\n",
        "    :effect (and (at ?o ?l) (arm-empty) (not (holding ?o)))\n",
        "  )\n",
        "\n",
        "  (:action turn-on\n",
        "    :parameters (?d ?o)\n",
        "    :precondition (and (off ?d) (at ?o ?d))\n",
        "    :effect (and (on ?d) (not (off ?d)) (filled ?o))\n",
        "  )\n",
        "\n",
        "  (:action turn-off\n",
        "    :parameters (?d)\n",
        "    :precondition (on ?d)\n",
        "    :effect (and (off ?d) (not (on ?d)))\n",
        "  )\n",
        "\n",
        "  (:action open\n",
        "    :parameters (?c)\n",
        "    :precondition (and (closed ?c))\n",
        "    :effect (and (open ?c) (not (closed ?c)))\n",
        "  )\n",
        "\n",
        "  (:action close\n",
        "    :parameters (?c)\n",
        "    :precondition (open ?c)\n",
        "    :effect (and (closed ?c) (not (open ?c)))\n",
        "  )\n",
        "\n",
        "  (:action place-in\n",
        "    :parameters (?o ?c)\n",
        "    :precondition (and (holding ?o) (open ?c) (container ?c))\n",
        "    :effect (and (at ?o ?c) (arm-empty) (not (holding ?o)))\n",
        "  )\n",
        ")\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "KLuf_i7sVI2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Save the PDDL domain into a file\n",
        "with open(\"./pddl_files/serveCoffee_domain.pddl\", \"w\") as f:\n",
        "    f.write(serve_coffee_domain)\n",
        "\n",
        "print(\"✅ serveCoffee_domain.pddl saved successfully!\")"
      ],
      "metadata": {
        "id": "tRM3iKm7dU33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct the PDDL Problem\n",
        "Create a **single problem file** (`serveCoffee_problem.pddl`) that references the domain you just wrote and contains three key sections—**Objects**, **Initial State**, and **Goal Conditions**—as described below.\n",
        "\n",
        "---\n",
        "\n",
        "### Objects (`:objects`)\n",
        "Declare every object (constant symbol) that participates in this specific planning instance.\n",
        "> 📌 Note: Use exactly the following names (no variations or additional objects):\n",
        ">\n",
        "> `mug` `coffeemachine` `countertop` `fridge`  \n",
        "---\n",
        "\n",
        "### Initial State (`:init`)  \n",
        "List all predicates that are **true** at the start of the episode.  \n",
        "> 📌 Note:\n",
        "> Even though the robotic arm is not visually rendered in the AI2-THOR scene, the planner should assume the agent starts in the arm-empty state.\n",
        "\n",
        "---\n",
        "\n",
        "### Goal Conditions (`:goal`)  \n",
        "Specify the conditions that must hold when planning finishes.  \n",
        "Wrap multiple predicates inside an `(and …)` expression."
      ],
      "metadata": {
        "id": "OStH7aV5VKQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the PDDL problem\n",
        "serve_coffee_problem = \"\"\"; serve-coffee_problem.pddl\n",
        "\n",
        "(define (problem serve-coffee-fridge)\n",
        "  (:domain serve-coffee)\n",
        "\n",
        "  (:objects\n",
        "    mug coffeemachine countertop fridge\n",
        "  )\n",
        "\n",
        "  (:init\n",
        "    (at          mug          countertop)\n",
        "    (off         coffeemachine)\n",
        "    (closed      fridge)\n",
        "    (arm-empty)\n",
        "    (surface     countertop)\n",
        "    (surface     coffeemachine)\n",
        "    (container   fridge)\n",
        "  )\n",
        "\n",
        "  (:goal\n",
        "    (and\n",
        "      (filled mug)\n",
        "      (at     mug fridge)\n",
        "    )\n",
        "  )\n",
        ")\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "XjzTxvGXVJ00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Save the PDDL problem into a file\n",
        "with open(\"./pddl_files/serveCoffee_problem.pddl\", \"w\") as f:\n",
        "    f.write(serve_coffee_problem)\n",
        "\n",
        "print(\"✅ serveCoffee_problem.pddl saved successfully!\")"
      ],
      "metadata": {
        "id": "0q9RZL_xdZ2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Run Planner & Inspect Solution\n",
        "\n",
        "We use **Pyperplan**, an open-source Python planner, to derive a plan from the PDDL files. It searches the state space with heuristic A* and saves the resulting action sequence to a .soln file for inspection and later execution."
      ],
      "metadata": {
        "id": "4qdWs6dLVOHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a plan and save it to a .soln file\n",
        "!pyperplan -l warning -s astar -H hff   ./pddl_files/serveCoffee_domain.pddl   ./pddl_files/serveCoffee_problem.pddl   > ./pddl_files/serveCoffee_problem.pddl.soln\n",
        "\n",
        "# Print the plan so you can verify the exact action sequence\n",
        "!cat ./pddl_files/serveCoffee_problem.pddl.soln"
      ],
      "metadata": {
        "id": "snKGn6OpVQ7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------------------\n",
        "# Main execution script\n",
        "# ---------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Initialize the AI2-THOR environment wrapper\n",
        "    thor = Thor(task_context, scenario_idx=-1, records_dir=\"test/serveCoffee/\")\n",
        "    time.sleep(1)  # brief pause to ensure the simulator is ready\n",
        "\n",
        "    # Read the planner output (.soln) and convert each line to a NL command\n",
        "    soln_path = \"pddl_files/serveCoffee_problem.pddl.soln\"\n",
        "    commands = thor.load_plan_from_soln(soln_path)\n",
        "\n",
        "    # Parse natural-language commands into concrete action objects\n",
        "    actions = []\n",
        "    for cmd in commands:\n",
        "        for action_cls in thor.action_space:\n",
        "            args = action_cls.parse(cmd)\n",
        "            if args is not None:\n",
        "                actions.append(action_cls(thor, args))\n",
        "                break\n",
        "\n",
        "    # Execute each action sequentially in the simulator\n",
        "    for idx, action in enumerate(actions, start=1):\n",
        "        print(f\"{idx}. Executing: {action}\")\n",
        "        action.execute()\n",
        "        thor.log(success=True, message=f\"after {action}\")"
      ],
      "metadata": {
        "id": "BBU-hbVNHhFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio, glob, os, numpy as np, PIL\n",
        "\n",
        "# Convert saved PNG frames into an MP4 video\n",
        "def make_video_from_frames(records_dir, output_fname=\"plan_execution.mp4\", fps=4):\n",
        "    img_dir = os.path.join(records_dir, \"ego_img\")\n",
        "    pngs = sorted(glob.glob(f\"{img_dir}/step_*.png\"),\n",
        "                  key=lambda p: int(os.path.splitext(os.path.basename(p))[0].split(\"_\")[-1]))\n",
        "    if not pngs:\n",
        "        print(\"No frames to make video.\")\n",
        "        return\n",
        "    out_path = os.path.join(records_dir, output_fname)\n",
        "    with imageio.get_writer(out_path, fps=fps) as writer:\n",
        "        for p in pngs:\n",
        "            img = PIL.Image.open(p).convert(\"RGB\")\n",
        "            writer.append_data(np.array(img))\n",
        "    print(f\"Saved video: {out_path}\")\n",
        "\n",
        "# Build the video\n",
        "if __name__ == \"__main__\":\n",
        "    make_video_from_frames(\n",
        "            records_dir=thor.records_dir,\n",
        "            output_fname=\"serveCoffee.mp4\",\n",
        "            fps=4\n",
        "        )"
      ],
      "metadata": {
        "id": "-eOQBkTKH-Sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Play the execution video for the serveCoffee plan\n",
        "from IPython.display import Video\n",
        "Video(\"test/serveCoffee/serveCoffee.mp4\", embed=True, width=400)"
      ],
      "metadata": {
        "id": "WVsPMTuWKhUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3: boilFood\n",
        "\n",
        "In this task, the agent must place a tomato in a pot, fill the pot with water using the faucet, and then heat the tomato on the stoveburner. The tomato becomes hot only if all conditions are satisfied: the pot is on the stove, contains water, and the tomato is inside the pot.\n",
        "\n",
        "The PDDL planner must reason over these conditional effects to generate a valid sequence of actions, which are then executed and visualized within the AI2-THOR kitchen environment."
      ],
      "metadata": {
        "id": "BwAYP0UB7yGG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Task Context & Environment Setup"
      ],
      "metadata": {
        "id": "2G6FBJlc7P24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task_context = {\n",
        "  \"task_idx\": 3,\n",
        "  \"task\": \"boilFood\",\n",
        "  \"scene\": \"FloorPlan1\",\n",
        "  \"robot_init_state\": {\n",
        "    \"position\": {\n",
        "      \"x\": -1.2,\n",
        "      \"y\": 0.9,\n",
        "      \"z\": -1.45\n",
        "    },\n",
        "    \"rotation\": {\n",
        "      \"x\": 0,\n",
        "      \"y\": 200.0,\n",
        "      \"z\": 0\n",
        "    },\n",
        "    \"horizon\": 40.0\n",
        "  },\n",
        "  \"objects_init_state\": [\n",
        "    {\n",
        "      \"objectType\": \"Pot\",\n",
        "      \"objectName\": \"Pot_5c47f775\",\n",
        "      \"position\": {\n",
        "        \"x\": -1.3,\n",
        "        \"y\": 0.95,\n",
        "        \"z\": -2.2\n",
        "      },\n",
        "      \"rotation\": {\n",
        "        \"x\": -0.0,\n",
        "        \"y\": 0.0,\n",
        "        \"z\": 0.0\n",
        "      },\n",
        "      \"property\": {}\n",
        "    },\n",
        "    {\n",
        "      \"objectType\": \"Pan\",\n",
        "      \"objectName\": \"Pan_21173d15\",\n",
        "      \"position\": {\n",
        "        \"x\": -1.0,\n",
        "        \"y\": 0.95,\n",
        "        \"z\": -2.2\n",
        "      },\n",
        "      \"rotation\": {\n",
        "        \"x\": 359.98,\n",
        "        \"y\": 0.01,\n",
        "        \"z\": 359.98\n",
        "      },\n",
        "      \"property\": {}\n",
        "    },\n",
        "    {\n",
        "      \"objectType\": \"Potato\",\n",
        "      \"objectName\": \"Potato_4dee147d\",\n",
        "      \"position\": {\n",
        "        \"x\": -1.66,\n",
        "        \"y\": 0.93,\n",
        "        \"z\": -2.15\n",
        "      },\n",
        "      \"rotation\": {\n",
        "        \"x\": 0.06,\n",
        "        \"y\": 0.0,\n",
        "        \"z\": 0.08\n",
        "      },\n",
        "      \"property\": {}\n",
        "    },\n",
        "    {\n",
        "      \"objectType\": \"Tomato\",\n",
        "      \"objectName\": \"Tomato_caaae6b0\",\n",
        "      \"position\": {\n",
        "        \"x\": -1.66,\n",
        "        \"y\": 0.93,\n",
        "        \"z\": -2.3\n",
        "      },\n",
        "      \"rotation\": {\n",
        "        \"x\": 0.0,\n",
        "        \"y\": 0.0,\n",
        "        \"z\": 0.0\n",
        "      },\n",
        "      \"property\": {}\n",
        "    }\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "id": "skt_YkU2epI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the AI2-THOR controller to load the specified scene\n",
        "# and configure rendering parameters\n",
        "controller.reset(\n",
        "    scene = task_context[\"scene\"],\n",
        "    visibilityDistance=1.5,\n",
        "    gridSize=0.05,\n",
        "    fieldOfView=90,\n",
        "    width=800,\n",
        "    height=500,\n",
        "    renderDepthImage=False,\n",
        "    renderNormalsImage=False,\n",
        "    renderInstanceSegmentation=False,\n",
        "    renderSemanticSegmentation=False\n",
        ")\n",
        "\n",
        "# Prepare and send object poses to the controller\n",
        "object_poses = []\n",
        "for object_init_state in task_context[\"objects_init_state\"]:\n",
        "    object_poses.append(\n",
        "        {\n",
        "            \"objectName\": object_init_state[\"objectName\"],\n",
        "            \"position\": object_init_state[\"position\"],\n",
        "            \"rotation\": object_init_state[\"rotation\"],\n",
        "        }\n",
        "    )\n",
        "controller.step(action=\"SetObjectPoses\", objectPoses=object_poses)\n",
        "controller.step(action=\"Done\")\n",
        "\n",
        "# Teleport the agent to its initial position and orientation\n",
        "controller.step(\n",
        "    action=\"Teleport\",\n",
        "    position=task_context['robot_init_state']['position'],\n",
        "    rotation=task_context['robot_init_state']['rotation'],\n",
        "    horizon=task_context['robot_init_state']['horizon'],\n",
        "    standing=True,\n",
        ")\n",
        "\n",
        "# Render and display the current camera view\n",
        "plot_frames(controller.last_event)"
      ],
      "metadata": {
        "id": "pmPahDHifCwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Define PDDL Domain & Problem\n",
        "\n",
        "### Construct the PDDL Domain\n",
        "\n",
        "Create a **single domain file** (`boilFood_domain.pddl`) that contains two sections—**Predicates** and **Action Schemas**—as described below.\n",
        "\n",
        "---\n",
        "\n",
        "### Predicates  \n",
        "List every **predicate**—that is, each unary or binary relationship/attribute—that can appear in the initial state, goal conditions, or within an action’s preconditions and effects.\n",
        "\n",
        "---\n",
        "\n",
        "### Action Schemas  \n",
        "Only **five** action names are permitted:\n",
        "\n",
        "1. `pick-up`  \n",
        "2. `place-on`  \n",
        "3. `place-in`\n",
        "4. `turn-off`\n",
        "5. `turn-on`\n",
        "> 📌 Note:  \n",
        "> **In this task, the turn-on action should behave differently depending on the device (e.g., faucet vs. stoveburner)**\n",
        ">\n",
        "> 🔹Use only one turn-on action\n",
        ">\n",
        "> 🔹Use `when` clauses to define conditional effects."
      ],
      "metadata": {
        "id": "BUWkCc_59B9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the PDDL domain\n",
        "boil_food_domain = \"\"\"; boil-food_domain.pddl\n",
        "\n",
        "(define (domain boilFood)\n",
        "  (:requirements :strips :conditional-effects :equality)\n",
        "\n",
        "  ;; ───── Constants ─────\n",
        "  ;; Fixed objects in the scene\n",
        "  (:constants tomato pot sink faucet stoveburner countertop)\n",
        "\n",
        "  ;; ───── Predicate Definitions ─────\n",
        "  (:predicates\n",
        "    (hand-empty)                  ;; The robotic hand is empty\n",
        "    (holding ?o)                  ;; The robot is holding object ?o\n",
        "\n",
        "    (on-top-of ?o ?s)             ;; Object ?o is on top of surface ?s\n",
        "    (in ?o ?c)                    ;; Object ?o is inside container ?c\n",
        "\n",
        "    (turned-on ?d)                ;; Device ?d is currently on\n",
        "    (turned-off ?d)               ;; Device ?d is currently off\n",
        "\n",
        "    (filled-with-water ?p)        ;; The pot ?p is filled with water\n",
        "    (hot ?o)                      ;; Object ?o is hot (applies to pot and tomato)\n",
        "\n",
        "    (faucet ?d)                   ;; Marks ?d as a faucet device\n",
        "    (stoveburner ?d)              ;; Marks ?d as a stove burner\n",
        "  )\n",
        "\n",
        "  ;; ── 1. pick up <object> ──────────────-\n",
        "  (:action pick-up\n",
        "    :parameters (?o ?loc)         ;; loc = surface or container\n",
        "    :precondition (and\n",
        "      (hand-empty)\n",
        "      (or (on-top-of ?o ?loc) (in ?o ?loc))\n",
        "    )\n",
        "    :effect (and\n",
        "      (holding ?o)\n",
        "      (not (hand-empty))\n",
        "      (not (on-top-of ?o ?loc))\n",
        "      (not (in ?o ?loc)))\n",
        "  )\n",
        "\n",
        "  ;; ── 2. place <object> in <container> ────────\n",
        "  (:action place-in\n",
        "    :parameters (?o ?c)\n",
        "    :precondition (holding ?o)\n",
        "    :effect (and\n",
        "      (in ?o ?c)\n",
        "      (hand-empty)\n",
        "      (not (holding ?o)))\n",
        "  )\n",
        "\n",
        "  ;; ── 3. place <object> on <surface> ──────────\n",
        "  (:action place-on\n",
        "    :parameters (?o ?s)\n",
        "    :precondition (holding ?o)\n",
        "    :effect (and\n",
        "      (on-top-of ?o ?s)\n",
        "      (hand-empty)\n",
        "      (not (holding ?o)))\n",
        "  )\n",
        "\n",
        "  ;; ── 4. turn on <device> ───────────────\n",
        "  (:action turn-on\n",
        "    :parameters (?d)\n",
        "    :precondition (turned-off ?d)\n",
        "    :effect (and\n",
        "        (turned-on ?d) (not (turned-off ?d))\n",
        "\n",
        "        ;; Faucet: fill pot with water if it is in the sink\n",
        "        (when (and (faucet ?d) (in pot sink))\n",
        "            (filled-with-water pot))\n",
        "\n",
        "        ;; Stove: heat the pot if it is on the burner and filled\n",
        "        (when (and (stoveburner ?d)\n",
        "                (on-top-of pot stoveburner)\n",
        "                (filled-with-water pot))\n",
        "            (hot pot))\n",
        "\n",
        "        ;; Stove: heat the tomato if pot is on burner, filled, and tomato is inside\n",
        "        (when (and (stoveburner ?d)\n",
        "                (on-top-of pot stoveburner)\n",
        "                (filled-with-water pot)\n",
        "                (in tomato pot))\n",
        "            (hot tomato)))\n",
        "  )\n",
        "\n",
        "  ;; ── 5. turn off <device> ────────────────────\n",
        "  (:action turn-off\n",
        "    :parameters (?d)\n",
        "    :precondition (turned-on ?d)\n",
        "    :effect (and\n",
        "      (turned-off ?d)\n",
        "      (not (turned-on ?d)))\n",
        "  )\n",
        ")\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "XXbX4fk7fEfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Save the PDDL domain into a file\n",
        "with open(\"./pddl_files/boilFood_domain.pddl\", \"w\") as f:\n",
        "    f.write(boil_food_domain)\n",
        "\n",
        "print(\"✅ boilFood_domain.pddl saved successfully!\")"
      ],
      "metadata": {
        "id": "rWc70oKzdnna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct the PDDL Problem\n",
        "Create a **single problem file** (`boilFood_problem.pddl`) that references the domain you just wrote and contains three key sections—**Objects**, **Initial State**, and **Goal Conditions**—as described below.\n",
        "\n",
        "---\n",
        "\n",
        "### Objects (`:objects`)\n",
        "Declare every object (constant symbol) that participates in this specific planning instance.\n",
        "> 📌 Note: Use exactly the following names (no variations or additional objects):\n",
        ">\n",
        "> `tomato` `pot` `faucet` `stoveburner` `countertop`\n",
        "---\n",
        "\n",
        "### Initial State (`:init`)  \n",
        "List all predicates that are **true** at the start of the episode.  \n",
        "> 📌 Note:\n",
        "> Even though the robotic arm is not visually rendered in the AI2-THOR scene, the planner should assume the agent starts in the arm-empty state.\n",
        "\n",
        "---\n",
        "\n",
        "### Goal Conditions (`:goal`)  \n",
        "Specify the conditions that must hold when planning finishes.  \n",
        "Wrap multiple predicates inside an `(and …)` expression."
      ],
      "metadata": {
        "id": "Wcfaf8FG_na3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the PDDL problem\n",
        "boil_food_problem = \"\"\"; boil-food_problem.pddl\n",
        "\n",
        "(define (problem boilFood_problem)\n",
        "  (:domain boilFood)\n",
        "\n",
        "  (:init\n",
        "    ;; The robot starts with an empty hand\n",
        "    (hand-empty)\n",
        "\n",
        "    ;; Tomato and pot are initially on the countertop\n",
        "    (on-top-of tomato countertop)\n",
        "    (on-top-of pot    countertop)\n",
        "\n",
        "    ;; Both devices (faucet and stoveburner) are off initially\n",
        "    (turned-off faucet)\n",
        "    (turned-off stoveburner)\n",
        "\n",
        "    ;; Declare device types (used for conditional effects)\n",
        "    (faucet faucet)\n",
        "    (stoveburner stoveburner)\n",
        "  )\n",
        "\n",
        "  (:goal\n",
        "    (and\n",
        "      ;; The tomato should be placed inside the pot\n",
        "      (in tomato pot)\n",
        "\n",
        "      ;; The pot must be hot (requires water + stove)\n",
        "      (hot pot)\n",
        "\n",
        "      ;; The tomato must also be hot (requires being in hot pot)\n",
        "      (hot tomato)\n",
        "\n",
        "      ;; The devices must be turned off\n",
        "      (turned-off faucet)\n",
        "      (turned-off stoveburner)\n",
        "    )\n",
        "  )\n",
        ")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "6B3cPtLCfP_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Save the PDDL problem into a file\n",
        "with open(\"./pddl_files/boilFood_problem.pddl\", \"w\") as f:\n",
        "    f.write(boil_food_problem)\n",
        "\n",
        "print(\"✅ boilFood_problem.pddl saved successfully!\")"
      ],
      "metadata": {
        "id": "R6WzFFghdt9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Run Planner & Inspect Solution\n",
        "\n",
        "We use **Fast Downward**, a high-performance planning system written in C++, to derive a plan from the PDDL domain and problem files. It explores the state space using various heuristics and search strategies.\n",
        "\n",
        "> ✅ Why We Use Fast Downward (instead of Pyperplan)\n",
        ">\n",
        "> Although Pyperplan is easy to set up and written in Python, it has limited support for PDDL features.\n",
        "In particular, it does not support conditional effects, such as the when clause used in the `turn-on` action of the boilFood task."
      ],
      "metadata": {
        "id": "CLuluFKSALyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required build tools (compiler, cmake, Python headers)\n",
        "!apt-get update -qq\n",
        "!apt-get install -y build-essential cmake g++ python3-dev\n",
        "\n",
        "# Clone the Fast Downward planning system (if not already cloned)\n",
        "!git clone https://github.com/aibasel/downward.git || echo \"repo exists\"\n",
        "\n",
        "# Build Fast Downward in release mode (optimized for speed)\n",
        "!cd downward && ./build.py -j2 release"
      ],
      "metadata": {
        "id": "kOfL5SK6tpWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /content/AI2THOR_ws/AI2THOR_ws/task_planning\n",
        "\n",
        "# Run Fast Downward planner using the default configuration (LAMA-2011 heuristic)\n",
        "# No explicit output file is specified; plan will be saved to \"sas_plan\"\n",
        "python3 downward/fast-downward.py \\\n",
        "    --alias seq-sat-lama-2011 \\\n",
        "    pddl_files/boilFood_domain.pddl \\\n",
        "    pddl_files/boilFood_problem.pddl"
      ],
      "metadata": {
        "id": "p3fDgMMyCK19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /content/AI2THOR_ws/AI2THOR_ws/task_planning\n",
        "\n",
        "# Get the most recently modified sas_plan* file (-t: sort by time, head -1: get latest)\n",
        "PLAN_FILE=$(ls -t sas_plan* | head -n 1)\n",
        "\n",
        "# Print and copy the latest plan file to a .soln file for inspection\n",
        "echo \"Copying $PLAN_FILE → pddl_files/boilFood_problem.pddl.soln\"\n",
        "cp \"$PLAN_FILE\" pddl_files/boilFood_problem.pddl.soln\n",
        "\n",
        "# Print the final task plan (action sequence) saved in the .soln file\n",
        "echo \"----------- plan -----------\"\n",
        "cat pddl_files/boilFood_problem.pddl.soln"
      ],
      "metadata": {
        "id": "v1K_uPvAGFxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/AI2THOR_ws/AI2THOR_ws/task_planning"
      ],
      "metadata": {
        "id": "eoa5t48pG-Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from ai2thor.controller import Controller\n",
        "from ai2thor.platform import Linux64, CloudRendering\n",
        "from actions import get_action_classes\n",
        "from plan_success_checker import check_task_success\n",
        "\n",
        "\n",
        "class Thor:\n",
        "    \"\"\"Thin wrapper around AI2-THOR’s Controller that:\n",
        "       • sets up the scene from a task-context dictionary\n",
        "       • executes high-level action classes (open, close, pick-up, …)\n",
        "       • logs events / RGB frames for later analysis or video creation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, task_context: dict, scenario_idx: int, records_dir: str):\n",
        "        \"\"\"Create a Thor helper and immediately initialize the simulator.\"\"\"\n",
        "        self.controller = None\n",
        "        self.counter = 0\n",
        "        self.task_context = task_context\n",
        "        self.records_dir = records_dir\n",
        "        self.log_archive = {}\n",
        "\n",
        "        # Available high-level actions (parsed from natural language commands).\n",
        "        self.action_space = get_action_classes()\n",
        "        self.init_env()\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # Environment setup\n",
        "    # ----------------------------------------------------------------------\n",
        "    def init_env(self):\n",
        "        \"\"\"Reset the AI2-THOR scene, place objects, and teleport the agent.\"\"\"\n",
        "        self.controller = Controller()\n",
        "        # Scene-level parameters (FOV, resolution, etc.)\n",
        "        self.controller.reset(\n",
        "            scene=self.task_context[\"scene\"],\n",
        "            visibilityDistance=1.5,\n",
        "            gridSize=0.05,\n",
        "            fieldOfView=90,\n",
        "            width=800,\n",
        "            height=500,\n",
        "            renderDepthImage=False,\n",
        "            renderNormalsImage=False,\n",
        "            renderInstanceSegmentation=False,\n",
        "            renderSemanticSegmentation=False,\n",
        "        )\n",
        "\n",
        "        # Place all task-specific objects at their initial poses\n",
        "        object_poses = [\n",
        "            {\n",
        "                \"objectName\": obj[\"objectName\"],\n",
        "                \"position\": obj[\"position\"],\n",
        "                \"rotation\": obj[\"rotation\"],\n",
        "            }\n",
        "            for obj in self.task_context[\"objects_init_state\"]\n",
        "        ]\n",
        "        self.controller.step(action=\"SetObjectPoses\", objectPoses=object_poses)\n",
        "        self.controller.step(action=\"Done\")\n",
        "\n",
        "        # Teleport the agent to its start pose (position, rotation, horizon)\n",
        "        self.controller.step(\n",
        "            action=\"Teleport\",\n",
        "            position=self.task_context[\"robot_init_state\"][\"position\"],\n",
        "            rotation=self.task_context[\"robot_init_state\"][\"rotation\"],\n",
        "            horizon=self.task_context[\"robot_init_state\"][\"horizon\"],\n",
        "            standing=True,\n",
        "        )\n",
        "        self.controller.step(action=\"Done\")\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # Convenience properties\n",
        "    # ----------------------------------------------------------------------\n",
        "    @property\n",
        "    def is_hand_empty(self) -> bool:\n",
        "        \"\"\"True if the agent is not holding any object.\"\"\"\n",
        "        return self.agent_state[\"isHolding\"] is None\n",
        "\n",
        "    @property\n",
        "    def agent_state(self) -> dict:\n",
        "        \"\"\"Return the current agent metadata with an extra 'isHolding' field.\"\"\"\n",
        "        event = self.controller.last_event\n",
        "        agent = event.metadata[\"agent\"]\n",
        "        agent[\"isHolding\"] = None\n",
        "        # Determine which object (if any) is currently picked up\n",
        "        for obj in self.objects_state:\n",
        "            if obj.get(\"pickupable\") and obj.get(\"isPickedUp\"):\n",
        "                agent[\"isHolding\"] = obj\n",
        "                break\n",
        "        return agent\n",
        "\n",
        "    @property\n",
        "    def objects_state(self) -> list:\n",
        "        \"\"\"Return metadata for all objects visible in the current frame.\"\"\"\n",
        "        return self.controller.last_event.metadata[\"objects\"]\n",
        "\n",
        "    @property\n",
        "    def rgb_frame(self) -> np.ndarray:\n",
        "        \"\"\"Return the current RGB image rendered by AI2-THOR.\"\"\"\n",
        "        return self.controller.last_event.frame\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # Object-lookup helpers\n",
        "    # ----------------------------------------------------------------------\n",
        "    def get_objectsByType(self, objectType: str) -> list:\n",
        "        \"\"\"Return all objects of a given AI2-THOR objectType.\"\"\"\n",
        "        return [o for o in self.objects_state if o[\"objectType\"].lower() == objectType.lower()]\n",
        "\n",
        "    def get_objectById(self, objectId: str):\n",
        "        \"\"\"Return a single object by its unique objectId (or None).\"\"\"\n",
        "        return next((o for o in self.objects_state if o[\"objectId\"] == objectId), None)\n",
        "\n",
        "    def get_objectByName(self, objectName: str):\n",
        "        \"\"\"Return a single object by its human-readable name (or None).\"\"\"\n",
        "        return next((o for o in self.objects_state if o[\"name\"] == objectName), None)\n",
        "\n",
        "    def get_closestObject(self, objects: list):\n",
        "        \"\"\"Given a list of objects, return the one closest to the agent.\"\"\"\n",
        "        agent_pos = self.agent_state[\"position\"]\n",
        "\n",
        "        def euclidean(p):\n",
        "            return ((p[\"x\"] - agent_pos[\"x\"]) ** 2 + (p[\"y\"] - agent_pos[\"y\"]) ** 2 + (p[\"z\"] - agent_pos[\"z\"]) ** 2) ** 0.5\n",
        "\n",
        "        return min(objects, key=lambda o: euclidean(o[\"position\"])) if objects else None\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # Logging utilities\n",
        "    # ----------------------------------------------------------------------\n",
        "    def log(self, success: bool, message: str):\n",
        "        \"\"\"Print and archive a log message for the current frame counter.\"\"\"\n",
        "        if not message:\n",
        "            return\n",
        "        tag = \"[INFO]\" if success else \"[ERROR]\"\n",
        "        msg = f\"Frame {self.counter:03d} | {tag} {message}\"\n",
        "        print(msg)\n",
        "        self.log_archive[self.counter] = msg\n",
        "\n",
        "    def save_data(self, log_flag: bool = True):\n",
        "        \"\"\"Save the current event + RGB frame and advance the frame counter.\"\"\"\n",
        "        if log_flag:\n",
        "            os.makedirs(f\"{self.records_dir}/events\", exist_ok=True)\n",
        "            with open(f\"{self.records_dir}/events/step_{self.counter}.pickle\", \"wb\") as f:\n",
        "                pickle.dump(self.controller.last_event, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "        os.makedirs(f\"{self.records_dir}/ego_img\", exist_ok=True)\n",
        "        plt.imsave(\n",
        "            f\"{self.records_dir}/ego_img/step_{self.counter}.png\",\n",
        "            np.asarray(self.rgb_frame, order=\"C\"),\n",
        "        )\n",
        "        self.counter += 1\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # Plan-parsing helpers\n",
        "    # ----------------------------------------------------------------------\n",
        "    def parse_word(self, line: str) -> str | None:\n",
        "        \"\"\"Convert a single PDDL action line into a natural-language command.\"\"\"\n",
        "        parts = line.strip(\"()\\n\").split()\n",
        "        mapping = {\n",
        "            \"pick-up\": lambda p: f\"pick up {p[1]}\",\n",
        "            \"place-in\": lambda p: f\"place {p[1]} in {p[2]}\",\n",
        "            \"place-on\": lambda p: f\"place {p[1]} on {p[2]}\",\n",
        "            \"open\": lambda p: f\"open {p[1]}\",\n",
        "            \"close\": lambda p: f\"close {p[1]}\",\n",
        "            \"turn-on\": lambda p: f\"turn on {p[1]}\",\n",
        "            \"turn-off\": lambda p: f\"turn off {p[1]}\",\n",
        "        }\n",
        "        return mapping.get(parts[0], lambda p: None)(parts)\n",
        "\n",
        "    def load_plan_from_soln(self, soln_path: str) -> list[str]:\n",
        "        \"\"\"Read a .soln file and return a list of natural-language commands.\"\"\"\n",
        "        commands = []\n",
        "        with open(soln_path) as f:\n",
        "            for line in f:\n",
        "                cmd = self.parse_word(line)\n",
        "                if cmd:\n",
        "                    commands.append(cmd)\n",
        "        return commands\n"
      ],
      "metadata": {
        "id": "xeIKKpJVT-67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------------------\n",
        "# Main execution script\n",
        "# ---------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Initialize the AI2-THOR environment wrapper\n",
        "    thor = Thor(task_context, scenario_idx=-1, records_dir=\"test/boilFood/\")\n",
        "    time.sleep(1)  # brief pause to ensure the simulator is ready\n",
        "\n",
        "    # Read the planner output (.soln) and convert each line to a NL command\n",
        "    soln_path = \"pddl_files/boilFood_problem.pddl.soln\"\n",
        "    commands = thor.load_plan_from_soln(soln_path)\n",
        "\n",
        "    # Parse natural-language commands into concrete action objects\n",
        "    actions = []\n",
        "    for cmd in commands:\n",
        "        for action_cls in thor.action_space:\n",
        "            args = action_cls.parse(cmd)\n",
        "            if args is not None:\n",
        "                actions.append(action_cls(thor, args))\n",
        "                break\n",
        "\n",
        "    # Execute each action sequentially in the simulator\n",
        "    for idx, action in enumerate(actions, start=1):\n",
        "        print(f\"{idx}. Executing: {action}\")\n",
        "        action.execute()\n",
        "        thor.log(success=True, message=f\"after {action}\")"
      ],
      "metadata": {
        "id": "ra-dvxoOfZBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio, glob, os, numpy as np, PIL\n",
        "\n",
        "# Convert saved PNG frames into an MP4 video\n",
        "def make_video_from_frames(records_dir, output_fname=\"plan_execution.mp4\", fps=4):\n",
        "    img_dir = os.path.join(records_dir, \"ego_img\")\n",
        "    pngs = sorted(glob.glob(f\"{img_dir}/step_*.png\"),\n",
        "                  key=lambda p: int(os.path.splitext(os.path.basename(p))[0].split(\"_\")[-1]))\n",
        "    if not pngs:\n",
        "        print(\"No frames to make video.\")\n",
        "        return\n",
        "    out_path = os.path.join(records_dir, output_fname)\n",
        "    with imageio.get_writer(out_path, fps=fps) as writer:\n",
        "        for p in pngs:\n",
        "            img = PIL.Image.open(p).convert(\"RGB\")\n",
        "            writer.append_data(np.array(img))\n",
        "    print(f\"Saved video: {out_path}\")\n",
        "\n",
        "# Build the video\n",
        "if __name__ == \"__main__\":\n",
        "    make_video_from_frames(\n",
        "            records_dir=thor.records_dir,\n",
        "            output_fname=\"boilFood.mp4\",\n",
        "            fps=4\n",
        "        )"
      ],
      "metadata": {
        "id": "5PP2hIpHfcnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Play the execution video for the boilFood plan\n",
        "from IPython.display import Video\n",
        "Video(\"test/boilFood/boilFood.mp4\", embed=True, width=800)"
      ],
      "metadata": {
        "id": "_hhgv3JDfe-k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}